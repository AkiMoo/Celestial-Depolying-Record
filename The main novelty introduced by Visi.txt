The main novelty introduced by Vision GNN architecture (ViG) [15] is the decoupling of the computational graph from
the image’s regular grid structure and sequential structures adopted by CNN and transformer-based architectures. Instead,
ViG splits the input image into several patches and projects them into a high-dimensional embedding space. The computational graph, i.e., the adjacency matrix adopted for the message passing in graph neural networks, is dynamically computed with a configurable number of neighbors based on similarity between embeddings. Each individual patch is treated as a node in a directed graph, with directed edges being created between the patch itself and the top-k most similar patches based on their embeddings. 

related works


计算机视觉中的主流网络架构过去通常是卷积网络[29, 27, 17]。从LeNet [29]开始，CNN在各种视觉任务中取得了成功应用，例如图像分类[27]、物体检测[42]和语义分割[36]。在过去的十年中，CNN架构发展迅速。代表性的工作包括ResNet [17]、MobileNet [21]和NAS [75, 70]。Vision Transformer是从2020年开始为视觉任务引入的[14, 9, 3, 4]。从那时起，提出了许多ViT [9]的变体以改善视觉任务的性能。主要改进包括金字塔架构[57, 35]、局部注意力[15, 35]和位置编码[61]。在Vision Transformer的启发下，MLP也在计算机视觉中得到了探索[49, 50]。通过特别设计的模块[5, 32, 12, 48]，MLP可以实现有竞争力的性能，并且适用于对象检测和分割等通用视觉任务。

2.2 图神经网络
最早的图神经网络最初在[11, 44]中概述。Micheli [38]通过组合非递归层构建了早期的基于空间的图卷积网络。近几年，基于空间的GCN的变体已经被引入，例如[39, 1, 10]。基于谱的GCN最早由Bruna等人提出[2]，它基于谱图理论引入了图卷积。自那时以来，已经提出了许多改进和扩展基于谱的GCN的工作[18, 7, 26]。GCN通常应用于图数据，例如社交网络[13]、引用网络[45]和生物化学图[55]。

GCN在计算机视觉领域的应用[63, 28, 56, 25]主要包括点云分类、场景图生成和动作识别。点云是空间中一组3D点，通常通过LiDAR扫描收集。GCN已经用于对点云进行分类和分割[28, 58, 69]。场景图生成旨在将输入图像解析成包含物体及其关系的图，通常通过结合物体检测器和GCN来解决[63, 68]。通过处理自然形成的关节连接图，GCN被用于人体动作识别任务[24, 67]。GCN只能处理具有自然构建图的特定视觉任务。对于计算机视觉中的一般应用，我们需要一个基于GCN的主干网络，直接处理图像数据。

Once the graph has been defined, information is processed by a neural message passing mechanism, namely Grapher layer, consisting of maxrelative graph convolution [36] with a 2-layer MLP with ReLU nonlinearities. 

RCB和RTCB部分
Figure2显示了语义压缩过程的架构，它由以下两个模块组成：残差卷积块（RCB）和残差转置卷积块（RTCB），残差结构有助于增强联合源通道编码能力。残差网络由卷积，反卷积层和PReLU激活函数构成，在卷积或转置卷积层之后使用的归一化操作是基于广义归一化变换（GDN）的局部除法归一化。在处理图像压缩和密度建模任务中已证明非常有效[29]。卷积或转置卷积层由参数m × n | s指定，其中m和n对应于使用的卷积核的宽度、高度，符号↓和↑表示下采样操作和上采样操作，参数s表示步长长度。本文中使用 5 × 5 的卷积核，采样步长为2。通过这样处理，能够有效压缩卫星发送端的数据量，同时一定程度保证地面站能通过收到的数据信息还原出图结构的特征。地面站接收到语义信息，然后通过像素上采样模块对特征信息升维；最后将与图结构维度相同的特征张量送入已经训练好的推理模块进行图像推理。


对于每个节点 v_i，我们找到其 K 个最近邻节点 N(v_i)，并在每个 v_j ∈ N(v_i) 上添加一条从 v_j 指向 v_i 的有向边 e_ji。这样我们就得到了一个图 G = (V, E)，其中 E 表示所有的边。




Vision GNN架构（ViG）\cite{han2022vision} 引入的主要创新点是将将输入图像分割成多个图块，并将它们投影到高维嵌入空间中。这样，就将图像的常规网格结构的顺序与旧有的框架解耦合（比如CNN以及基于Transformer的架构）。对于一个大小为 H × W × Channel 的图像，我们将其分割成 N 个图块。通过将每个图块转换为一个特征向量 xi ∈ ℝ^D，我们得到 X = [x₁, x₂, ..., x_N]，其中 D 是特征维度，i = 1, 2, ..., N 表示图块的索引。
  计算图，即在图神经网络中用于消息传递的邻接矩阵，是根据嵌入之间的相似性动态计算的，并且可以根据需要配置邻居数量。每个图块被视为有向图中的一个节点，根据它们的嵌入，与自身和与之最相似的前k个图块之间建立有向边。
为了表示节点的位置信息，我们向每个节点特征添加一个位置编码向量：xi <- xi + ei (8) 
其中ei是一个维度为D的向量。绝对位置编码如公式8所描述的方式应用于各向同性和金字塔架构。
一旦定义了图，信息将通过神经消息传递机制（即Grapher层）进行处理，其中包括使用ReLU非线性函数的两层MLP的最大相对图卷积[36]。Grapher层具体如下：

为了通用性，我们从特征XRN D开始。我们首先基于这些特征构建一个图：G = G(X)。图卷积层可以通过聚合相邻节点的特征来交换节点之间的信息。具体而言，图卷积的操作如下所示：
G = F(GW) = WUpdate(G,Wagg)
其中，Wagg和Wupdate分别是聚合和更新操作的可学习权重。更具体地说，聚合操作通过聚合相邻节点的特征来计算节点的表示，而更新操作进一步合并聚合的特征：
这里我们采用了最大相对图卷积（max-relative graph convolution）[30]，因为它简单高效：
xi' = Wupdate [ximax( xj - xij, N(xi) ),Wagg]其中N(xi)是节点xi的相邻节点集合。
定义grapher(X) = for all xi in X
为了缓解深层GCN中的过度平滑现象，同样在ViG模块中引入了更多的特征变换和非线性激活。
在图卷积之后插入非线性激活函数，以避免层的崩溃。
实际上，对于给定的输入特征X RN D，Grapher模块可以表示为：
Y = FWb   theta((GrapherFWnb(X)))    (6)
为了进一步增强特征变换能力并缓解过度平滑现象，我们在每个节点上使用前馈网络（FFN）。
Z = FWb   theta(FWnb(Y)))  (7)
F Wnb 和 F Wb 分别表示没有偏置项和具有偏置项的两个带有权重的全连接层，σ 表示 ReLU 非线性激活函数。
Y 和 Z 表示 Grapher 学习到的图块嵌入，在前馈神经网络（FFN）模块投影之前和投影之后的状态，其中 X 是输入图块的嵌入。


ViG编码器由一系列的Grapher模块和卷积层组成，每个卷积层将输入的分辨率减半，即在每个Grapher模块和卷积模块之后，图块的数量减少了4倍。值得注意的一点是，ViG根据输入图像和图块嵌入动态地构建图。每个图块被视为输入图中的一个节点，由其图块嵌入来描述。ViG在每个Grapher层自动构建一个不同的图，通过计算每个图块与其他所有图块之间的距离来完成。给定预定义的邻居数 K，每个图块与其 K 个最近邻图块以有向方式相连。更具实际意义的是，给定两个输入图像 xi 和 xj，以及相同的图块 h xh_i、xh_j，与图块 xh_i 相邻的图块与图块 xh_j 的邻居可能在不同的位置上。图块的位置不直接参与边的创建，位置信息仅通过图块嵌入间接地间接考虑。在图像处理任务中，金字塔架构随着网络的加深逐渐缩小特征图的空间大小，利用图像的尺度不变性产生多尺度特征（例如ResNet [17] 和PVT [57]。），提高了模型的性能[15]。在本次语义通信模型设计实现的Vig编码模块也是使用 PyramidViG 架构，并在第四部分中简称为 ViG。金字塔架构。一方面，金字塔结构可以提高性能和精度，另一方面，在金字塔结构逐层压缩的过程中，数据量逐级减少，对于卫星地面站的语义通信系统是有利的。最后，图像分类推理任务是在 ViG 编码器的top使用一个分类头完成的，该分类头由一个池化层和 MLP 分类器组成。


本工作对ViG - pyramid的【vig】架构进行了修订。在第一步的特征提取先将图块的高度和宽度缩小到原有的四分之一，然后在每一个 Grapher 层之后，中间表示的高度和宽度减半，每一步将图块数量减少了4倍。为了解决这个问题，我们修改了 ViG 的编码器结构，使其具有与原始实现相似数量的可学习参数，并避免了图块数量方面的模型崩溃。具体而言，我们将 Grapher 的阶段数从 4 减少到 3，分别使用维度为 [64, 128, 256] 的嵌入空间，而不是原始实现中的 [48, 96, 240, 384]（ViG-Tiny）。此外，我们将头的数量从 4 增加到 16，并在每个 Grapher 层的图形创建中保持 K = 9 的层数。每个数据集的模型大小在第四部分中介绍，并有所不同。其中一个数据集沿用了【vigeo】使用过的bigearthnet，这个基准数据集的输入图像分辨率较低（120x120像素），为了避免模型崩溃到单个图块上，首步的宽度不是减少四倍，而是和经过Grapher层的处理一样，对图块数量进行减半处理。
结果的 ViG 架构示意图如图2所示。

本次实验在三个开放的土地覆盖分类基准数据集上对ViG-语义通信系统的性能进行了评估：其中两个是多类别分类数据集RESISC45 [18] 和 PatternNet [19]，另一个多标签分类数据集BigEarthNet。前两个数据集是都是由分辨率为256x256像素的仅RGB获取的数据。这两个数据集使用Google Earth收集，分别提供了31500和30400张卫星图像。RGB数据集完全平衡，分别包含45个和38个不同的类别，每个类别分别包含700和800个样本。RESISC45 数据集的分辨率范围从每像素0.2到30米，而PatternNet的分辨率范围从每像素6到50厘米。RESISC45 数据集的获取涵盖了100多个国家，图像条件在天气、地形形态特征和光照方面具有很高的变异性。后一个数据集是一个大规模的多标签图像场景分类数据集，即BigEarthNet [16]，[17]，BigEarthNet 中最高分辨率的通道尺寸为120x120像素，空间分辨率从每像素60米到10米不等，具体取决于光谱波段。较低分辨率的获取数据使用双线性插值上采样以匹配最高分辨率，获得了所有分辨率为120x120像素的输入图像。BigEarthNet 数据集提供了两个高度不平衡的标签集：一个较简单的任务由19个标签组成，一个较难的任务由43个不同的类别组成。我们采用了较难的标签集，考虑了更具挑战性的任务。

在本文的语义通信系统中，将Vig语义通信的图像处理模块与另外两个模型进行了比较，分别是ResNet和ViT。具体而言，对于ResNet和ViT，实验设置是将图片编码压缩，传输后再进行图像重建的方法，以达到与vig-语义通信系统的相似条件。
本文的实验选择了ViG-Tiny模型，它有7.1M个可训练参数。类似地，我们选择了ResNet18和ViT-Tiny模型进行比较（分别为11M和5.5M），这是因为相对于ViG-Tiny和ResNet34、ViT-Small和ViT-Base的大小较大（分别为21.7M、22M和86M）。模型大小与数据集的比较如表II所示。

ViG-Tiny在BigEarthNet和RESISC45之间可训练参数的数量差异归因于两个原因：
（i）首先第一个原因是因为图像的输入通道的数量不同，分别是3通道和12通道，
（ii）以及RESISC45和PatternNet这两个数据集有着更高的输入分辨率（以像素为单位），这导致了更多的参数分配给可学习的位置编码向量。

我们选择了AdamW优化器，并为所有数据集和模型的训练过程设置了学习率为10^-4的参数。权重衰减的范围在10^-2和10^-4之间，并且最多进行100个epochs。训练过程中使用交叉熵损失进行优化。训练超参数的摘要如表III所示。
#此外，我们采用了早停机制，通过监控验证损失来进行，如果连续10个epochs的验证损失没有改善，就会减小学习率的因子为10，并设置了5个epochs的耐心期。#

在本节中，我们比较了三个模型在三个数据集上进行的结果，分别是多类别分类（两个数据集）和多标签分类（一个数据集）。由于两种情况下的类别平衡度不同，我们在第一种情况下评估了宏平均指标，而在后一种情况下评估了微平均分数。
我们针对每个实验测试了F1-Score、召回率、精确度和准确度。

多类别分类：本文考虑的多类别分类问题代表了中等规模数据集的较简单任务。表IV显示了宏平均的F1、精确度和召回率分数。此外，我们还计算了每个模型的每类指标的最大值和最小值。
从PatterNet上获得的结果可以看出，所考虑的图像分类任务相对于RESISC45来说难度较低。所有模型的得分都高于99.0，其中ViT是三者中最差的。ResNet和ViG的F1、精确度和召回率分数相似，而ViT的指标低于0.63。然而，在评估最小每类情况时，ViG的最小召回率为97.62，比ViT高出5.06个百分点（pp），比ResNet高出0.89pp。综合考虑所有指标，视觉GNN模型在所有指标上取得了最好的成绩，除了最小精确度指标，ResNet在该指标上表现优于ViG。

实验结果实际上表明，在解决RESISC45中提出的分类任务时，存在更高的复杂性，ViG模型获得了最大平均F1分数为86.34，比ViT和ResNet分别高出10.27pp和2.65pp。在考虑最低每类指标时，ViG在F1、精确度和召回率方面分别比ViT高出17.44pp、13.64pp和21.91pp，差距进一步增大。

总体而言，基于图结构学习图像表示在中等规模数据集的土地覆盖分类中表现出了最先进的性能，从而证实了基于Transformer的架构的主要限制，即需要大量数据来学习更好的图像表示。

多标签分类：在BigEarthNet数据集上的实验证实了ViG架构在多光谱成像和遥感方面的学习能力（包括RGB、红外和超蓝信息的12个输入通道）。在这种情况下，考虑到所有三个微平均指标，ViG表现出更好的性能，其次是ViT（F1提升了0.21pp），而ResNet则表现最差（提升了2.85pp），尽管它的可训练参数数量较少，相较于IV-E1节中的实验。这是由于图像中补丁数量显著减少，因此与位置编码张量相关联的参数数量也减少了。


待用段落

将图像视为图数据的优势包括：1) 图是一种广义的数据结构，网格和序列可以被视为图的特例；2) 图相比于网格或序列更灵活，可以更好地建模复杂对象，因为图像中的对象通常不是正方形，形状是不规则的；3) 一个对象可以被视为由多个部分组成（例如，一个人可以粗略地分为头部、上半身、手臂和腿部），而图结构可以构建这些部分之间的连接；4) 对GNN的先进研究成果可以应用于解决视觉任务。

多年来，研究人员提出了一些基于数据推断的方法，包括无监督和有监督的方法。[26]评估了基于遥感数据获取的不同聚类算法用于地表覆盖分类，[27]提出了模糊聚类算法用于地表覆盖分类。类似地，[28]提出了一种基于ISODATA算法的混合方法来进行土地利用分类。然而，研究界还调查了监督方法的应用，例如随机森林[29]和支持向量机（SVM）[30]。
————————————————————————————————

Related works

在遥感文献中，将大规模地表特征的识别和监测（包括自然和人为资源）称为地表覆盖与土地利用分类问题。多年来，研究人员提出了许多不同的方法，从开发特定的光谱指数自动识别植被[20]、水体[21]和烧毁区域[22]开始。领域专家利用不同光谱波段对地面元素的响应特性来制定诸如NDVI和NDWI之类的指数，以监测植被、水体和冰川的状态[23][24]。因此，这些光谱成像转换定义了具有多个波段的数学变换，为每个像素生成单一标量值。但是此类方法对噪声非常敏感，需要特定的阈值校准，并且可能因形态、物候特征和生物群落[25]而有所不同，不能直接从数据中推断出来。

随着数据可用性的增加，以及大规模基准数据集[17][31]的存在和神经网络取得的更好性能，领域专家开始将计算机视觉模型调整到航空图像领域，证明了更优越的性能。纯卷积模型如ResNet[32]在包括地表覆盖分类在内的多种任务中展示了最先进的性能[33]。最近，研究界开始研究在遥感领域应用基于Transformer的模型，在数据充足的情况下证实了比CNNs更好的性能[10]。在文献中，出现了一些基于视觉图神经网络（Vision GNNs）的应用，但仅限于小规模数据集[34][35]。据我们所知，本文首次将一种名为ViG的视觉图神经网络引入大规模遥感多标签基准测试，并将其适应于遥感领域。
图像推理任务中的特征金字塔结构对数据量来说是压缩处理，

ViG每层特征提取能减少数据量，对于致力迫切将图片数据在较短回传到地面的卫星通信场景正是有需要的。


计算机视觉中的主流网络架构过去通常采用卷积网络[29、27、17]。从LeNet [29]开始，CNN已成功应用于各种视觉任务，如图像分类[27]、目标检测[42]和语义分割[36]。过去十年间，CNN架构发展迅速，代表性的工作包括ResNet [17]、MobileNet [21]和NAS [75、70]。视觉Transformer是从2020年开始为视觉任务引入的[14、9、3、4]。从那时起，提出了许多ViT [9]的变体来提高视觉任务的性能。主要改进包括金字塔结构[57、35]、局部注意力[15、35]和位置编码[61]。受视觉Transformer的启发，MLP也被应用于计算机视觉[49、50]。通过专门设计的模块[5、32、12、48]，MLP可以在对象检测和分割等通用视觉任务上实现竞争性能。

2.2 图神经网络
GCN在计算机视觉领域的应用[63、28、56、25]主要包括点云分类、场景图生成和动作识别。点云是空间中的一组3D点，通常通过LiDAR扫描收集。GCN已用于对点云进行分类和分割[28、58、69]。场景图生成旨在将输入图像解析为包含对象及其关系的图形，通常通过结合目标检测器和GCN来解决[63、68]。通过处理自然形成的关节连接图，GCN被用于人体动作识别任务[24、67]。GCN只能处理具有自然构建图的特定视觉任务。对于计算机视觉中的通用应用，我们需要一个基于GCN的主干网络，直接处理图像数据。


卫星通信可以提供大规模连接和无缝覆盖，但也面临一些挑战，例如雨衰减、长传播延迟和共信道干扰。为了提高传输效率并解决严峻的场景，语义通信会是一个不错的选择。


在本研究中，我们介绍了一种基于基础模型的语义卫星通信框架，称为FMSAT。该框架利用基于基础模型的分割和重构，显著减少了带宽需求，并在高噪声和干扰下准确恢复语义特征。并且提出了一种新颖的错误检测方法，用于在再生卫星上粗略检测语义错误。Semantic Satellite Communications Based on Generative Foundation Model

然而，将SemCom集成到SEC网络中以进行用户计算卸载会引入语义编码器更新要求以及额外的语义提取成本。通过SemCom在SEC网络中卸载用户计算还会带来新的功能挑战，例如延迟、能耗和隐私等方面。在本文中，我们提出了一种新颖的用于资源受限用户的计算卸载的SemCom辅助SEC（SemCom-SEC）框架。然后，我们提出了一种自适应修剪-分割联邦学习（PSFed）方法，用于更新SemCom-SEC中的语义编码器。我们进一步展示了该方法保证了训练的收敛速度和准确性。该方法还提高了语义编码器的隐私性，同时减少了训练延迟和能耗。对于已经训练好的语义编码器，对于处理计算任务的用户，主要目标是最小化用户的延迟和能耗，同时保持用户的隐私和公平性。然后，将该问题形式化为一个不完全信息的混合整数非线性规划（MINLP）问题。还提出了一种基于Rubinstein讨价还价博弈的新的计算任务处理调度（CTPS）机制。仿真结果证明，所提出的PSFed和博弈论的CTPS机制优于基准解决方案，可以减少延迟和能耗，同时增强用户的隐私。
Semantic Communication in Satellite-Borne Edge Cloud Network for Computation Offloading

作为实现6G全球接入的重要技术，低地球轨道卫星（LEO-Sat）通信仍面临频谱资源稀缺和严重多普勒效应等挑战。为了改善LEO-Sat系统中的图像传输性能，本文提出了一种将语义通信与正交时频空（OTFS）调制相结合的方法，以有效缓解严重的多普勒效应并提高传输效率。采用3GPP中的NTN-TDL-D模型来模拟卫星信道，并将噪声引入语义模型的训练过程中。进一步在不同条件下评估了语义增强和传统LEO-Sat系统的性能。最终的仿真结果表明，与现有解决方案相比，所提出的解决方案实现了至少6dB的信噪比增益，减少了50%的通信开销，并确保在高速场景下更高的频谱利用效率。
Semantic-Enhanced Downlink LEO Satellite Communication System with OTFS Modulation

我们提出了一种从现有的通信网络架构和评估方式中脱离出来的愿景，通过将信息的语义纳入考虑。在这里，我们定义信息的语义不仅仅是指消息的含义，还包括其在数据交换目的下的重要性，可能在实时约束条件下进行考量。我们认为，研究工作必须着重于为网络系统的信息生成、传输和使用过程重新设计奠定理论基础。这需要开发先进的语义度量标准，用于通信和控制系统；同时，还需要建立一种综合了信号稀疏性和及时性的最优采样理论，以实现在通信约束和延迟条件下的实时预测、重构和控制；此外，还需要在压缩域内进行决策和推理的时间有效的压缩感知技术；以及在数据生成、信道编码、分组化、反馈以及多路访问方案等方面考虑语义感知，从而减少数据量和能耗，并增加可支持设备的数量。这种范式转变旨在实现网络系统中信息收集、传播和决策的联合最优策略。
Semantic Communications in Networked Systems: A Data Significance Perspective



IN A WIRELESS communication system, source coding
 and channel coding are two commonly used techniques
 for improving communication efficiency and reliability respec
tively. In general, source coding is usually conducted at the
 application layer, and it is helpful for decreasing the data
 amount by reducing the information redundancy of the original
 source data. For image data compression tasks, traditional
 source coding methods mainly use the following three steps to
 reduce data amount: transform, quantization and entropy cod
ing, such as the well-known Discrete Cosine Transform (DCT)
 based Joint Photographic Experts Group (JPEG) [1] and Better
 Portable Graphics (BPG) [2] standards, and Discrete Wavelet
 Transform (DWT) based JPEG2000 standard [3]. Channel
 coding generally works at the physical layer, and it is mainly
 used for improving the transmission reliability by using error
 check or error correcting coding techniques, such as Low
 Density Parity Check Code (LDPC) [4], Polar code [5], and
 Turbo code [6]. In conventional communication systems, the
 above two coding processes are implemented as two separate
 functional modules or blocks, and this practice is helpful for
 designing, developing, and maintaining the communication
 system in a flexible way.
 From the perspective of system-level optimality, the above
 separable or layered source-channel coding paradigm is actu
ally suboptimal because it is designed and optimized indepen
dently without considering the mutual impacts, thus cannot
 work cooperatively to achieve the best overall communication
 capacity [7]. For example, the source decoding block assume
 that its input code from channel decoding block is error-free,
 and then it can recover the transmitted data without error
 from the result of channel decoding. However, when channel
 SNR is low and channel decoding is not able to guarantee
 the zero bit error rate, the quality of the recovering result
 will be dramatically reduced. This problem is called as the
 ’cliff-effect’, and it widely exists in conventional wireless
 communication systems [8], [9], [10].
 To solve the above problem, joint source-channel coding
 (JSCC) has been proposed by jointly designing and opti
mizing source coding and channel coding process to achieve
 system-level optimality for the coding process [11], [12], [13].
 Due to the advances of deep learning (DL) in recent years, it is
 practical for us to use the powerful data compression and noise
 resiliency capabilities of DL models to realize the end-to-end
 JSCC process with one DL model [14], [15], [16], and recent
 advances have demonstrated that DL based JSCC (DeepJSCC)
 methods, particularly deep autoencoder based JSCC methods,
 can achieve exciting capacities in both data compression and
 transmission reliability for various wireless data transmission
 tasks, such as image [9], text [17], and speech [18].
 For wireless image transmission tasks, in the conventional
 communication paradigm, an image may be firstly compressed
 by using the JPEG/JPEG2000 source coding methods and
 then transformed as noise-resiliency channel code by using
 a channel coding method like LDPC. At the receiver, the
 transmitted bits can be recovered without errors by using
 the corresponding channel decoding and source decoding
 processes when channel SNR is not too low. In the frame
work of DeepJSCC, the source channel coding and decoding
 processes are jointly completed by using an encoder and
 a decoder respectively, and the encoder-decoder pair (EDP)
 is trained in an end-to-end way, along with a non-trainable
 physical channel. In this way, the whole wireless transmission
 process is optimized from the original input image data and
 recovered output image data, thus it is globally optimal, and
 recent works have shown that this DeepJSCC-enabled wire
less transmission scheme can achieve superior data compres
sion performance compared with traditional JPEG/JPEG2000
 methods. In addition, it can achieve significant reliability
 performance improvement against channel noise compared
 with conventional communication scheme, especially in low
 SNR regime [9], [19], [20].
 In [9], deep convolutional neural network based autoen
coders are firstly used to realize joint source-channel coding
 for wireless image transmission, and recent advances have
 shown that the capability of DeepJSCC models can be further
 enhanced by using channel output feedback [10] and refine
ment transmission methods [21], [22]. However, as a new
 emerged methodology, the above proposed DeepJSCC models
 suffer from the following two problems: